{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "\n",
    "class DocumentRetrievalReranker:\n",
    "    def __init__(self, openai_api_key: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the document retrieval and reranking system.\n",
    "        \n",
    "        Args:\n",
    "            openai_api_key: OpenAI API key (if not provided, will use env variable)\n",
    "        \"\"\"\n",
    "        if openai_api_key:\n",
    "            os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        \n",
    "        # Initialize embeddings and chat model\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "        \n",
    "        # Vector store (will be initialized with documents)\n",
    "        self.vectorstore = None\n",
    "        \n",
    "        # Reranking prompt template\n",
    "        self.rerank_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert document ranker. Given a user question and a list of documents, \n",
    "rerank the documents based on their relevance to the question.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Documents:\n",
    "{documents}\n",
    "\n",
    "Please rank these documents from most relevant to least relevant by returning only \n",
    "the document numbers separated by commas (e.g., \"3,1,5,2,4\").\n",
    "\n",
    "Consider:\n",
    "1. Direct relevance to the question\n",
    "2. Completeness of information\n",
    "3. Quality and specificity of content\n",
    "4. Practical applicability\n",
    "\n",
    "Return only the ranking numbers, no explanation:\n",
    "\"\"\")\n",
    "        \n",
    "        # Create the reranking chain\n",
    "        self.rerank_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.rerank_prompt\n",
    "        )\n",
    "    \n",
    "    def load_documents(self, documents: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Load documents into the vector store.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of document texts\n",
    "        \"\"\"\n",
    "        # Convert strings to Document objects\n",
    "        doc_objects = [Document(page_content=doc) for doc in documents]\n",
    "        \n",
    "        # Create FAISS vector store\n",
    "        self.vectorstore = FAISS.from_documents(doc_objects, self.embeddings)\n",
    "        print(f\"‚úÖ Loaded {len(documents)} documents into vector store\")\n",
    "    \n",
    "    def retrieve_documents(self, query: str, k: int = 6) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Retrieve top-k documents using vector similarity search.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of retrieved documents\n",
    "        \"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"No documents loaded. Call load_documents() first.\")\n",
    "        \n",
    "        retrieved_docs = self.vectorstore.similarity_search(query, k=k)\n",
    "        print(f\"üîç Retrieved {len(retrieved_docs)} documents for query: '{query}'\")\n",
    "        return retrieved_docs\n",
    "    \n",
    "    def format_documents_for_ranking(self, documents: List[Document]) -> str:\n",
    "        \"\"\"\n",
    "        Format documents for the reranking prompt.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of Document objects\n",
    "            \n",
    "        Returns:\n",
    "            Formatted string with numbered documents\n",
    "        \"\"\"\n",
    "        formatted = []\n",
    "        for i, doc in enumerate(documents, 1):\n",
    "            formatted.append(f\"{i}. {doc.page_content}\")\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "    \n",
    "    def rerank_documents(self, query: str, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Rerank documents using LLM-based scoring.\n",
    "        \n",
    "        Args:\n",
    "            query: Original query\n",
    "            documents: List of retrieved documents\n",
    "            \n",
    "        Returns:\n",
    "            List of reranked documents\n",
    "        \"\"\"\n",
    "        # Format documents for the prompt\n",
    "        formatted_docs = self.format_documents_for_ranking(documents)\n",
    "        \n",
    "        # Get reranking from LLM\n",
    "        response = self.rerank_chain.invoke({\n",
    "            \"question\": query,\n",
    "            \"documents\": formatted_docs\n",
    "        })\n",
    "        \n",
    "        # Parse the response to extract indices\n",
    "        indices = self._parse_ranking_response(response[\"text\"], len(documents))\n",
    "        \n",
    "        # Rerank documents based on LLM response\n",
    "        reranked_docs = [documents[i] for i in indices if 0 <= i < len(documents)]\n",
    "        \n",
    "        print(f\"üéØ Reranked {len(reranked_docs)} documents\")\n",
    "        return reranked_docs\n",
    "    \n",
    "    def _parse_ranking_response(self, response: str, num_docs: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Parse the LLM ranking response to extract document indices.\n",
    "        \n",
    "        Args:\n",
    "            response: Raw response from LLM\n",
    "            num_docs: Number of documents to validate against\n",
    "            \n",
    "        Returns:\n",
    "            List of document indices (0-based)\n",
    "        \"\"\"\n",
    "        # Extract numbers from response\n",
    "        numbers = re.findall(r'\\d+', response)\n",
    "        \n",
    "        # Convert to 0-based indices and validate\n",
    "        indices = []\n",
    "        for num_str in numbers:\n",
    "            idx = int(num_str) - 1  # Convert to 0-based\n",
    "            if 0 <= idx < num_docs and idx not in indices:\n",
    "                indices.append(idx)\n",
    "        \n",
    "        # Add any missing indices to ensure all documents are included\n",
    "        for i in range(num_docs):\n",
    "            if i not in indices:\n",
    "                indices.append(i)\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    def search_and_rerank(self, query: str, k: int = 6) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Complete pipeline: retrieve and rerank documents.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of documents to retrieve initially\n",
    "            \n",
    "        Returns:\n",
    "            List of reranked documents\n",
    "        \"\"\"\n",
    "        # Step 1: Retrieve documents\n",
    "        retrieved_docs = self.retrieve_documents(query, k)\n",
    "        \n",
    "        # Step 2: Rerank documents\n",
    "        reranked_docs = self.rerank_documents(query, retrieved_docs)\n",
    "        \n",
    "        return reranked_docs\n",
    "    \n",
    "    def display_results(self, documents: List[Document], title: str = \"Results\") -> None:\n",
    "        \"\"\"\n",
    "        Display the results in a formatted way.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of documents to display\n",
    "            title: Title for the results section\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìä {title}:\")\n",
    "        print(\"=\" * 50)\n",
    "        for i, doc in enumerate(documents, 1):\n",
    "            print(f\"\\nRank {i}:\")\n",
    "            print(\"-\" * 20)\n",
    "            print(doc.page_content)\n",
    "\n",
    "\n",
    "# Example usage and demonstration\n",
    "def main():\n",
    "    # Sample documents about LangChain\n",
    "    sample_documents = [\n",
    "        'LangChain supports tool integration including web search, calculators, and APIs, allowing LLMs to interact with external systems and respond more accurately to dynamic queries. Memory in LangChain enables context retention across multiple steps in a conversation or task, making the application more coherent and stateful.',\n",
    "        \n",
    "        'LangChain is a flexible framework designed for developing applications powered by large language models (LLMs). It provides tools and abstractions to work with LLMs more effectively and includes components for prompt management, chains, memory, and agents.',\n",
    "        \n",
    "        'LangChain integrates with many third-party services such as OpenAI, Hugging Face, and Cohere. This enables developers to experiment with different models and optimize performance for specific use cases like summarization, question answering, or translation.',\n",
    "        \n",
    "        'FAISS is a popular library used for fast approximate nearest neighbor search in high-dimensional spaces. It supports both flat and compressed indexes, which makes it scalable for large document stores. Agents in LangChain are chains that use LLMs to decide which tools to use and in what order. This makes them suitable for multi-step tasks like question answering with search and code execution.',\n",
    "        \n",
    "        'Retrieval-Augmented Generation (RAG) is a powerful technique where external knowledge is retrieved and passed into the prompt to ground LLM responses. LangChain makes it easy to implement RAG using vector databases like FAISS, Chroma, and Pinecone. BM25 is a traditional sparse retrieval method that scores documents based on keyword matching. Although fast, it often struggles with synonyms and semantic similarity.',\n",
    "        \n",
    "        'Dense retrieval uses embeddings to match query and documents in a vector space. This allows capturing semantic meaning, making it useful for fuzzy or natural language queries. LangChain supports hybrid retrieval by combining BM25 and dense similarity scores. This approach improves both precision and recall in document search.'\n",
    "    ]\n",
    "    \n",
    "    # Initialize the system\n",
    "    print(\"üöÄ Initializing Document Retrieval and Reranking System...\")\n",
    "    \n",
    "    # Note: You'll need to set your OpenAI API key\n",
    "    # retriever = DocumentRetrievalReranker(openai_api_key=\"your-api-key-here\")\n",
    "    \n",
    "    # For demo purposes, we'll show the structure\n",
    "    print(\"\\nüìö Sample Documents Loaded:\")\n",
    "    for i, doc in enumerate(sample_documents, 1):\n",
    "        print(f\"{i}. {doc[:100]}...\")\n",
    "    \n",
    "    # Example queries to test\n",
    "    test_queries = [\n",
    "        \"How does RAG work with LangChain?\",\n",
    "        \"What are agents in LangChain?\",\n",
    "        \"Tell me about vector databases and FAISS\",\n",
    "        \"How does LangChain integrate with external services?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüîç Example Queries to Test:\")\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"{i}. {query}\")\n",
    "    \n",
    "    print(\"\\nüí° To use this system:\")\n",
    "    print(\"1. Set your OpenAI API key\")\n",
    "    print(\"2. Initialize: retriever = DocumentRetrievalReranker()\")\n",
    "    print(\"3. Load documents: retriever.load_documents(your_documents)\")\n",
    "    print(\"4. Search and rerank: results = retriever.search_and_rerank(your_query)\")\n",
    "    print(\"5. Display results: retriever.display_results(results)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9073b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/databases/company.db', 'table_name': 'employees', 'num_records': 4, 'data_type': 'sql_table'}, page_content=\"Table: employees\\nColumns: id, name, role, department, salary\\nTotal Records: 4\\n\\nSample Records:\\n{'id': 1, 'name': 'John Doe', 'role': 'Senior Developer', 'department': 'Engineering', 'salary': 95000.0}\\n{'id': 2, 'name': 'Jane Smith', 'role': 'Data Scientist', 'department': 'Analytics', 'salary': 105000.0}\\n{'id': 3, 'name': 'Mike Johnson', 'role': 'Product Manager', 'department': 'Product', 'salary': 110000.0}\\n{'id': 4, 'name': 'Sarah Williams', 'role': 'DevOps Engineer', 'department': 'Engineering', 'salary': 98000.0}\\n\"),\n",
       " Document(metadata={'source': 'data/databases/company.db', 'table_name': 'projects', 'num_records': 4, 'data_type': 'sql_table'}, page_content=\"Table: projects\\nColumns: id, name, status, budget, lead_id\\nTotal Records: 4\\n\\nSample Records:\\n{'id': 1, 'name': 'RAG Implementation', 'status': 'Active', 'budget': 150000.0, 'lead_id': 1}\\n{'id': 2, 'name': 'Data Pipeline', 'status': 'Completed', 'budget': 80000.0, 'lead_id': 2}\\n{'id': 3, 'name': 'Customer Portal', 'status': 'Planning', 'budget': 200000.0, 'lead_id': 3}\\n{'id': 4, 'name': 'ML Platform', 'status': 'Active', 'budget': 250000.0, 'lead_id': 2}\\n\"),\n",
       " Document(metadata={'source': 'data/databases/company.db', 'data_type': 'sql_relationships', 'query': 'employee_project_join'}, page_content='Employee-Project Relationships:\\n\\nJohn Doe (Senior Developer) leads RAG Implementation - Status: Active\\nJane Smith (Data Scientist) leads Data Pipeline - Status: Completed\\nMike Johnson (Product Manager) leads Customer Portal - Status: Planning\\nJane Smith (Data Scientist) leads ML Platform - Status: Active\\n')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql_to_documents(\"data/databases/company.db\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
