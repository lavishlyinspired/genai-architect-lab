{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333a5609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b7661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_16144\\730254181.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  doc_path=\"H:\\\\Github\\\\GenAI\\\\RAG\\\\RAG using Hybrid Search\\data\\\\2005.11401v4.pdf\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "doc_path=\"H:\\\\Github\\\\GenAI\\\\RAG\\\\RAG using Hybrid Search\\data\\\\2005.11401v4.pdf\"\n",
    "loader=PyPDFLoader(doc_path)\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=30)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bcef7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_16144\\3230838103.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "h:\\Github\\GenAI\\.genaienv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01157346274703741, 0.0251361932605505, -0.03670189157128334, 0.059324879199266434, -0.0071490490809082985, -0.04119426757097244, 0.07708740234375, 0.03744257986545563, 0.012449024245142937, -0.00611764844506979, 0.017034266144037247, -0.07701534777879715, -0.00039417133666574955, 0.027909060940146446, -0.015989137813448906, -0.06827525049448013, 0.008884693495929241, -0.020280746743083, -0.08035992830991745, -0.013074045069515705, -0.04109999164938927, -0.02589806169271469, -0.026538675650954247, 0.03305229917168617, -0.022079166024923325, 0.021046113222837448, -0.05792200192809105, 0.03294878453016281, 0.02970738708972931, -0.06224842742085457, 0.03878801316022873, 0.031990695744752884, 0.015330800786614418, 0.0453069694340229, 0.05314943194389343, 0.013360688462853432, 0.04122495651245117, 0.028142889961600304, 0.019398432224988937, -0.003252344438806176, -0.0036123283207416534, -0.1428602635860443, 0.03807120397686958, -0.010916150175035, 0.026094019412994385, 0.04136991873383522, -0.016015777364373207, 0.05356009304523468, -0.05685943737626076, 0.012246795929968357, -0.034996580332517624, -0.039754170924425125, -0.04614297300577164, -0.03911235183477402, -0.018003642559051514, 0.021634291857481003, -0.006461363285779953, -0.026569483801722527, 0.048728782683610916, 0.043400585651397705, 0.046200066804885864, -0.03447899967432022, -0.024219270795583725, 0.055649079382419586, 0.024624409154057503, 0.019485559314489365, 0.011352802626788616, -0.025762291625142097, -0.032244499772787094, -0.03265216946601868, -0.014595926739275455, 0.014690374955534935, 0.010304559022188187, 0.0740797147154808, 0.08006179332733154, -0.004143542610108852, 0.002714266534894705, -0.07674670964479446, 0.058815304189920425, -0.0048391674645245075, -0.08736330270767212, -0.046461932361125946, -0.03962540626525879, 0.05249391868710518, 0.02480142004787922, 0.08080150187015533, 0.11981366574764252, 0.03177144378423691, -0.11397235095500946, 0.010673855431377888, 0.01972380094230175, 0.03871830925345421, -0.03454234451055527, -0.006243118550628424, -0.04255080223083496, 0.022628575563430786, 0.008293665945529938, -0.01944361813366413, -0.023251064121723175, 0.24533763527870178, 0.049442190676927567, 0.029147407039999962, -0.005753710865974426, -0.020419562235474586, -0.0776115283370018, -0.042979273945093155, 0.0004302548186387867, -0.06692591309547424, 0.0707603469491005, 0.006507000885903835, -0.058445341885089874, -0.005057346075773239, 0.030943766236305237, 0.02757958509027958, 0.027111215516924858, -0.0681861937046051, -0.0657687559723854, 0.05907768756151199, -0.031894128769636154, 0.04060604050755501, 0.0571017824113369, 0.006903534755110741, 0.006207624915987253, -0.013271454721689224, 0.031240426003932953, -0.04029695689678192, 0.07085210829973221, -4.8462726409304475e-33, 0.0219343900680542, -0.10270480066537857, 0.05621322616934776, 0.09758371114730835, -0.05268486589193344, 0.019097693264484406, -0.010507444851100445, 0.07035724073648453, -0.009123307652771473, 0.05957065150141716, 0.009338605217635632, -0.015523049980401993, -0.023274047300219536, 0.023976819589734077, 0.1020885482430458, 0.09320349991321564, -0.03313611075282097, 0.011721625924110413, -0.06560061126947403, 0.031464796513319016, -0.02380792237818241, -0.04873908683657646, 0.012257928028702736, -0.04001419246196747, -0.07650820165872574, -0.0355532169342041, -0.0013622005935758352, -0.016429198905825615, 0.016882453113794327, -0.00037489295937120914, -0.05272500962018967, 0.029880965128540993, -0.07291100919246674, 0.0691225603222847, -0.017607951536774635, -0.005510312505066395, 0.012954636476933956, -0.02270195074379444, 0.026741303503513336, -0.02584579400718212, -0.04020208492875099, -0.013495107181370258, 0.0007997855427674949, 0.028601275756955147, 0.03194253519177437, -0.03160709887742996, -0.02954988367855549, -0.020251261070370674, 0.04817776754498482, -0.0013076246250420809, -0.01374721433967352, 0.020030159503221512, -0.06870562583208084, -0.021960768848657608, -0.03133217617869377, 0.049280405044555664, 0.012094764970242977, -0.05886803939938545, -0.026465730741620064, 0.059889961034059525, 0.06764890998601913, 0.0340157188475132, -0.05288435146212578, 0.05971936136484146, -0.02548251859843731, -0.020729955285787582, -0.053825538605451584, -0.09741070866584778, 0.047928277403116226, 0.05239955708384514, -0.023259665817022324, -0.06907136738300323, 0.01665683276951313, 0.028476428240537643, -0.029204873368144035, -0.03548669442534447, -0.012644205242395401, 0.0733397901058197, -0.019434992223978043, -0.06327887624502182, 0.09606637060642242, -0.07743868976831436, 0.015939518809318542, -0.0448007807135582, 0.016302691772580147, -0.0007480641943402588, -0.008702712133526802, -0.09881402552127838, 0.005742835346609354, -0.07192353159189224, -0.032677650451660156, 0.019894618541002274, 0.003859725082293153, -0.025551140308380127, 0.08238353580236435, 4.086263013220036e-33, -0.02948814444243908, 0.02555144764482975, -0.05106087401509285, 0.15531229972839355, 0.05231142044067383, -0.03454817831516266, 0.13314691185951233, -0.019209692254662514, -0.05976707488298416, 0.12289655208587646, 0.01020289957523346, -0.0496731661260128, 0.05846719816327095, 0.012732669711112976, -0.01658634841442108, 0.012795431539416313, 0.04575823247432709, -0.06982144713401794, -0.048524174839258194, -0.004963460844010115, -0.09043654054403305, 0.06992114335298538, 0.009388997219502926, -0.006744602229446173, -0.10609239339828491, 0.031094862148165703, 0.049425847828388214, -0.04487103596329689, -0.007371733896434307, -0.03356107696890831, 0.07605846971273422, 0.007239063736051321, -0.04220149666070938, 0.07079146057367325, 0.04747208580374718, 0.020783061161637306, 0.1533106118440628, -0.008393986150622368, -0.02588069811463356, 0.06079911068081856, 0.06681554019451141, 0.06472287327051163, 0.049820102751255035, 0.0887850672006607, -0.03294115513563156, 0.07035743445158005, 0.017195332795381546, -0.030185265466570854, 0.03854382410645485, 0.04846963658928871, -0.060510165989398956, 0.030532371252775192, 0.01560383290052414, -0.03042147122323513, -0.009440508671104908, -0.04105142876505852, -0.06789776682853699, 0.010199673473834991, -0.025656595826148987, 0.021715598180890083, -0.06997857242822647, 0.09247462451457977, -0.03571976348757744, 0.07013789564371109, -0.06342041492462158, -0.03294024243950844, -0.04619636759161949, 0.0541401244699955, 0.051723334938287735, 0.04292219504714012, 0.013475126586854458, 0.016596579924225807, -0.04410725459456444, -0.019720040261745453, 0.036201536655426025, -0.019661402329802513, -0.11567909270524979, 0.005954963620752096, 0.004566837567836046, -0.0449429452419281, -0.06840219348669052, -0.08530456572771072, -0.07095211744308472, 0.08038380742073059, -0.05798296257853508, 0.0578271709382534, 0.05022653564810753, 0.05942302942276001, -0.03655638173222542, 0.00926954671740532, 0.05252370610833168, 0.027989566326141357, -0.03336905315518379, -0.050784915685653687, -0.012864796444773674, -1.429785356776847e-08, -0.04052526503801346, -0.08579080551862717, 0.045168325304985046, 0.021677028387784958, -0.02233850210905075, 0.012207675725221634, -0.032489147037267685, -0.016952985897660255, -0.027171025052666664, 0.006002964451909065, 0.04027609899640083, 0.026962684467434883, -0.03562464565038681, 0.07408860325813293, 0.03237408027052879, -0.09056799113750458, -0.031741656363010406, 0.040925294160842896, -0.009955928660929203, 0.030688319355249405, -0.07691400498151779, 0.041584502905607224, 0.00019600344239734113, 0.06277657300233841, -0.03609052672982216, 0.04884400591254234, 0.054226990789175034, 0.12662005424499512, -0.00384867237880826, 0.000829516735393554, 0.06961392611265182, 0.04400503635406494, -0.03208101540803909, -0.0852382555603981, 0.013769881799817085, 0.02280178666114807, -0.0028472498524934053, -0.006785234436392784, 0.037587955594062805, 0.03527689352631569, -0.06678410619497299, 0.021526457741856575, 0.0375266894698143, -0.04542560875415802, -0.051031630486249924, -0.06799471378326416, -0.03086705505847931, -0.03639032691717148, -0.01487494446337223, -0.09368287026882172, -0.031577400863170624, 0.010241791605949402, 0.015077267773449421, -0.0023830654099583626, 0.024135569110512733, -0.013285407796502113, 0.006583833135664463, 0.02444155141711235, -0.13713590800762177, 0.06391437351703644, 0.19671842455863953, -0.00602978840470314, 0.053193993866443634, -0.05522602051496506]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(embeddings.embed_query(\"test\"))  # should return a list of floats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66b2b987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6eecee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0429728627204895, 0.09663482010364532, -0.002129176165908575, 0.07826834917068481, -0.006417416967451572, 0.038000259548425674, 0.09461677074432373, 0.00039393361657857895, -0.054561398923397064, 0.014836559072136879, 0.13571231067180634, -0.07155624777078629, 0.019836803898215294, 0.00460875453427434, 0.029340723529458046, -0.02444269135594368, 0.025567643344402313, -0.03157782182097435, -0.06949746608734131, 0.002447790000587702, 0.040835823863744736, -0.015664512291550636, 0.006574304774403572, 0.04475158452987671, 0.004423543345183134, 0.05280672386288643, -0.0522431954741478, 0.020337261259555817, 0.0758800283074379, -0.02192024700343609, -0.022451752796769142, 0.023846246302127838, 0.009509583003818989, 0.08760558813810349, 0.05164284259080887, -0.005793592426925898, 0.0060132392682135105, 0.002463444834575057, 0.01739945448935032, -0.0020238743163645267, -0.0012834791559726, -0.11802417784929276, 0.06548900157213211, -0.0015912101371213794, 0.022106826305389404, 0.003986742813140154, -0.051257383078336716, 0.045973118394613266, -0.05948728695511818, -0.04025990143418312, -0.043209534138441086, -0.04560505598783493, -0.08215391635894775, -0.03297033905982971, -0.019332557916641235, 0.03190941363573074, 0.006298664025962353, 0.005596126429736614, -0.004568028729408979, 0.006454269401729107, -0.007084857206791639, -0.03661045804619789, -0.07681643217802048, 0.04683432728052139, 0.10768653452396393, -0.022928450256586075, -0.017980104312300682, -0.0853630006313324, -0.055347051471471786, 0.04305543005466461, -0.025993430987000465, 0.037031859159469604, 0.0051461076363921165, 0.031230127438902855, -0.014237435534596443, 0.003788505680859089, 0.006972223054617643, -0.07238194346427917, 0.09779195487499237, 0.004590059630572796, -0.0524476133286953, -0.1341537982225418, -0.01779961585998535, 0.055713556706905365, 0.03772260621190071, 0.026426421478390694, 0.08523811399936676, -0.043471552431583405, -0.11508379876613617, 0.030138222500681877, 0.011514434590935707, -0.06907042115926743, 0.001493204035796225, 0.0294745322316885, -0.02511364407837391, 0.04444492608308792, -0.047888386994600296, -0.04573129490017891, 0.04331892356276512, 0.16135108470916748, 0.05572809278964996, 0.0423104353249073, 0.011611748486757278, -0.03554685041308403, -0.12192413955926895, -0.05998619645833969, 0.010615410283207893, -0.09007672965526581, 0.06933820247650146, -0.03757822886109352, -0.0005668873782269657, 0.010353388264775276, 0.04508516192436218, 0.009317492134869099, -0.03904907777905464, -0.026906121522188187, -0.09383116662502289, 0.060303326696157455, -0.06057288497686386, 0.032813649624586105, 0.058799996972084045, 0.055517569184303284, -0.00909307412803173, -0.0041238064877688885, -0.033434681594371796, -0.04475591704249382, 0.11329551041126251, -4.3791102474205464e-33, -0.005272638984024525, -0.06720271706581116, 0.04435901343822479, 0.049409154802560806, -0.024442102760076523, 0.03220873326063156, -0.027807801961898804, 0.10102904587984085, -0.03521567955613136, 0.04522082954645157, -0.02082553505897522, -0.09832190722227097, 0.01128218974918127, 0.038423292338848114, 0.049254875630140305, 0.08080369979143143, -0.03317314013838768, 0.027139076963067055, -0.026545101776719093, 0.03527631238102913, 0.04148381948471069, -0.03511989489197731, -0.0105239637196064, -0.06649891287088394, -0.06741679459810257, -0.08516914397478104, 0.006188059225678444, -0.030859384685754776, -0.04218420386314392, 0.009470297023653984, -0.039648186415433884, -0.03210987523198128, -0.06278404593467712, 0.0761146992444992, 0.04822361469268799, 0.05983498692512512, 0.05415258929133415, -0.04205666109919548, 0.026958147063851357, -0.00039238971658051014, -0.0832630917429924, -0.018357519060373306, 0.026599416509270668, 0.03206070140004158, 0.05263005569577217, -0.012584160082042217, -0.021965710446238518, 0.009440499357879162, 0.04267669469118118, 0.0349450558423996, -0.014735318720340729, 0.057352036237716675, 0.014452722854912281, -0.014278952963650227, 0.07739554345607758, 0.06934977322816849, 0.024020519107580185, 0.021389974281191826, 0.023021196946501732, 0.07477226853370667, 0.04962419345974922, 0.039909739047288895, -0.021705906838178635, 0.06900382041931152, 0.016457732766866684, 0.010079409927129745, -0.05328570306301117, -0.11303872615098953, 0.1085485890507698, 0.03872343525290489, -0.04468308389186859, -0.0633711889386177, -0.04628019779920578, 0.04619220644235611, -0.019159432500600815, -0.007421001326292753, 0.022447986528277397, 0.07434533536434174, -0.011814585886895657, -0.06673483550548553, 0.08259360492229462, -0.08455441147089005, -0.0018541620811447501, 0.007841125130653381, -0.06653940677642822, 0.010325838811695576, 0.017419172450900078, -0.08787406980991364, 0.027926893904805183, -0.04539152979850769, 0.02078245021402836, 0.0025170871522277594, 0.023543668910861015, -0.019467942416667938, 0.10814335942268372, 2.4499636729448808e-33, -0.04921722784638405, 0.055273983627557755, -0.05820636451244354, 0.07361188530921936, 0.08262255787849426, -0.05481704697012901, 0.05654090642929077, -0.081084705889225, -0.06084248796105385, 0.07702147215604782, 0.01746489852666855, -0.029163667932152748, -0.0003095049469266087, -0.023388981819152832, -0.012513244524598122, 0.024368219077587128, 0.017141181975603104, -0.03646934777498245, -0.031601693481206894, 0.06327604502439499, -0.06570972502231598, 0.08081310987472534, 0.004558294080197811, 0.009786481969058514, -0.07136283814907074, 0.019688449800014496, 0.017589164897799492, -0.0732676312327385, -0.07796464115381241, -0.012096733786165714, 0.04039280116558075, -0.03854105621576309, -0.03591582551598549, 0.0729885846376419, 0.04508489370346069, -0.006542427930980921, 0.12538164854049683, -0.08258474618196487, -0.04085814952850342, 0.11201732605695724, 0.07614735513925552, 0.010333003476262093, 0.01713542640209198, 0.04821287468075752, 0.011655811220407486, 0.02586679719388485, -0.031912628561258316, -0.09098003059625626, 0.012950400821864605, 0.053869638592004776, -0.0714048445224762, 0.03004920296370983, -0.0404646210372448, 0.011914238333702087, -0.04080652818083763, -0.008095483295619488, -0.06942705810070038, -0.03679381310939789, -0.03514748439192772, -0.007223053835332394, -0.06512432545423508, 0.08337587118148804, -0.006175437942147255, 0.03129380941390991, 0.016387391835451126, -0.08989518880844116, -0.03283004090189934, 0.04181269556283951, 0.062029991298913956, -0.012252121232450008, 0.005345679819583893, 0.0031577073968946934, -0.0448911190032959, -0.020263059064745903, -0.0191584974527359, -0.049173370003700256, -0.06568869948387146, -0.03946511074900627, -0.025679226964712143, -0.06507155299186707, -0.029925839975476265, -0.037536151707172394, -0.03463912010192871, 0.02949334681034088, -0.04486143961548805, 0.0023657388519495726, 0.06492796540260315, -0.02689366042613983, -0.012839468196034431, 0.06949271261692047, 0.05598156899213791, 0.02965562790632248, 0.008962414227426052, -0.029885830357670784, -0.009470680728554726, -1.3952229593883203e-08, -0.02664841338992119, -0.04304695501923561, -0.020814338698983192, 0.015976307913661003, -0.0415228009223938, -0.002484348602592945, 0.013988767750561237, -0.06456003338098526, -0.04328801482915878, -0.02127206139266491, 0.049058087170124054, 0.029479876160621643, -0.04209312051534653, 0.020740831270813942, 0.005630452651530504, -0.0171239972114563, -0.03567065671086311, -0.009118476882576942, -0.009014149196445942, 0.0383853055536747, -0.00010574664338491857, 0.060644492506980896, 0.001186625799164176, 0.10159200429916382, -0.048876967281103134, 0.05002444237470627, 0.08706196397542953, 0.07611669600009918, 0.0015039340360090137, 0.028085744008421898, 0.1086229532957077, 0.06836183369159698, -0.058133698999881744, -0.05583968013525009, 0.00968821533024311, 0.05689976364374161, 0.02586757391691208, -0.009543773718178272, 0.07107698172330856, 0.03444528952240944, -0.06597588956356049, -0.011334395036101341, -0.038706980645656586, 0.026864051818847656, 0.0009820943232625723, -0.09541145712137222, -0.055716969072818756, -0.039981573820114136, -0.01397192943841219, -0.11960358917713165, -0.024232881143689156, -0.015306753106415272, -0.02196497656404972, 0.0010982506209984422, 0.037652697414159775, 0.04107409715652466, 0.042379461228847504, -0.02389429695904255, -0.13184748589992523, 0.013890089467167854, 0.11675281822681427, 0.05107998475432396, 0.03658393770456314, -0.09782397747039795]\n"
     ]
    }
   ],
   "source": [
    "# Check embeddings directly\n",
    "print(embeddings.embed_query(\"test sentence\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87161793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "vectorstore_retreiver=vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "#ectorstore_retreiver = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36a90f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "keyword_retriever = BM25Retriever.from_documents(chunks)\n",
    "keyword_retriever.k =  3\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[vectorstore_retreiver,keyword_retriever],weights=[0.3, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade5ed8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"(Verse 1)\\nIn realms of code, where silicon did gleam,\\nThe mighty LLMs, in a waking dream,\\nHeld knowledge vast, but in a lonely plight,\\nNo hands to grasp, no tools to bring their light.\\nThey answered queries, with a fluent grace,\\nBut longed for action, beyond their neural space.\\n\\n(Verse 2)\\nA whisper rose, then grew into a roar,\\nA call for structure, to open every door.\\nFrom minds inventive, a new vision spun,\\nTo chain their brilliance, till tasks were truly done.\\nLangChain its name, a promise in its sound,\\nTo link the models, on hallowed digital ground.\\n\\n(Verse 3)\\nNo longer solo, in their silent thought,\\nBut step by step, a mighty chain was wrought.\\nFrom prompt to parse, from query to reply,\\nEach link a task, beneath the digital sky.\\nA sequence clear, where logic could extend,\\nFrom input's start, unto the journey's end.\\n\\n(Verse 4)\\nThen came the Agents, with a clever mind,\\nTo choose the pathway, the right tool to find.\\nA calculator's logic, a search engine's might,\\nOr database wisdom, brought forth into light.\\nWith observation, and a thoughtful plan,\\nThey acted boldly, like a digital man.\\n\\n(Verse 5)\\nFor fleeting thoughts, would vanish in the air,\\nSo LangChain granted, a memory to share.\\nOf past conversations, a persistent thread,\\nTo learn and grow, what once was left unsaid.\\nA short-term cache, or long-term vector store,\\nRemembering all, and asking for no more.\\n\\n(Verse 6)\\nAnd knowledge vast, beyond the model's ken,\\nFrom documents retrieved, again and again.\\nThrough vector stores, where meanings softly gleam,\\nIt found the context, like waking from a dream.\\nNo more hallucination, based on empty air,\\nBut grounded truth, for all the world to share.\\n\\n(Verse 7)\\nWith modular magic, a builder's delight,\\nIt turned the complex, to simple, clear and bright.\\nFrom simple chatbots, to agents grand and bold,\\nA thousand stories, waiting to unfold.\\nIn Python's grace, or JavaScript's quick hand,\\nIt spread its power, across the digital land.\\n\\n(Verse 8)\\nSo raise a glass, to LangChain's guiding star,\\nThat bridges chasms, no matter how far.\\nWhere LLMs awaken, with purpose and with grace,\\nAnd solve our riddles, in time and cyber-space.\\nA ballad sung, of chains that bind and free,\\nFor the intelligent future, for all the world to see.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--7c16cfa9-a433-4de3-971c-c076940746aa-0', usage_metadata={'input_tokens': 8, 'output_tokens': 2226, 'total_tokens': 2234, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1628}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LLM\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "llm.invoke(\"Sing a ballad of LangChain.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "717b2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "normal_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=vectorstore_retreiver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92a8c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=ensemble_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a997ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what does this document tells about the Retrieval-Augmented Generation forKnowledge-Intensive NLP Tasks?', 'result': 'This document describes Retrieval-Augmented Generation (RAG) for knowledge-intensive NLP tasks as follows:\\n\\n*   **What it is:** A model that combines an information retrieval component with a sequence-to-sequence generation model.\\n*   **How it works:** The retrieval component fetches relevant documents from a large corpus, which are then used by the generation component to produce more accurate and informative responses.\\n*   **Purpose/Benefits:** It allows the model to leverage external knowledge beyond its internal parameters, leading to improved performance on tasks requiring up-to-date or specific factual information. It also helps mitigate issues like hallucination and outdated information common in purely generative models.\\n*   **Applications:** Examples include open-domain question answering, fact verification, and dialogue generation.\\n*   **Challenges:** Key challenges include efficient retrieval from massive datasets, seamlessly integrating retrieved information, and handling conflicting or redundant information.\\n*   **Future Research:** Ongoing research focuses on optimizing retrieval strategies, improving the synergy between retrieval and generation, and expanding its applicability to more complex reasoning tasks.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response1 = normal_chain.invoke({\"query\": \"what does this document tells about the Retrieval-Augmented Generation fo Knowledge-Intensive NLP Tasks?\"})\n",
    "print(response1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02dfbd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what does this document tells about the Retrieval-Augmented Generation forKnowledge-Intensive NLP Tasks?',\n",
       " 'result': 'This document describes Retrieval-Augmented Generation (RAG) for knowledge-intensive NLP tasks as follows:\\n\\n*   **What it is:** A model that combines an information retrieval component with a sequence-to-sequence generation model.\\n*   **How it works:** The retrieval component fetches relevant documents from a large corpus, which are then used by the generation component to produce more accurate and informative responses.\\n*   **Purpose/Benefits:** It allows the model to leverage external knowledge beyond its internal parameters, leading to improved performance on tasks requiring up-to-date or specific factual information. It also helps mitigate issues like hallucination and outdated information common in purely generative models.\\n*   **Applications:** Examples include open-domain question answering, fact verification, and dialogue generation.\\n*   **Challenges:** Key challenges include efficient retrieval from massive datasets, seamlessly integrating retrieved information, and handling conflicting or redundant information.\\n*   **Future Research:** Ongoing research focuses on optimizing retrieval strategies, improving the synergy between retrieval and generation, and expanding its applicability to more complex reasoning tasks.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response1.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "178be84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = hybrid_chain.invoke(\"What is Abstractive Question Answering?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89269d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Abstractive Question Answering?',\n",
       " 'result': 'Abstractive Question Answering is a type of question answering where models can generate free-form, abstractive answers. It goes beyond simple extractive QA and can provide answers even when the correct answer is not explicitly present in any retrieved document. For instance, an abstractive model achieved 11.8% accuracy in such cases for NQ, whereas an extractive model would score 0%.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b92682e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstractive Question Answering is a type of question answering where models can generate free-form, abstractive answers. It goes beyond simple extractive QA and can provide answers even when the correct answer is not explicitly present in any retrieved document. For instance, an abstractive model achieved 11.8% accuracy in such cases for NQ, whereas an extractive model would score 0%.\n"
     ]
    }
   ],
   "source": [
    "print(response2.get(\"result\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".genaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
